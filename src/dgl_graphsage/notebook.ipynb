{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82fbeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from scipy import sparse as sp\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import re\n",
    "import networkx as nx\n",
    "from torch.nn.functional import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d4b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cd5244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jiw033/teams/DSC180A_FA21_A00/a13group1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('./teams/DSC180A_FA21_A00/a13group1')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eaa8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = './features/merged_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e16d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(G, feat_dir, normalize=True):\n",
    "    data = np.genfromtxt(feat_dir, delimiter=',', skip_header=True, dtype=str)\n",
    "    features = np.array(np.delete(data[:,2:], -3, 1), dtype=float)\n",
    "    if normalize:\n",
    "        features = F.normalize(torch.Tensor(features), dim=0)\n",
    "    uris = data[:, 1]\n",
    "    uris = [re.sub('spotify:track:', '', uri) for uri in uris]\n",
    "    uri_map = {n: i for i,n in enumerate(uris)}\n",
    "\n",
    "    src, dest = [], [] \n",
    "    adj_list = defaultdict(set)    \n",
    "    for e in G.edges:\n",
    "        u,v = uri_map[e[0]], uri_map[e[1]]\n",
    "        adj_list[u].add(v)\n",
    "        adj_list[v].add(u)\n",
    "        src.append(u)\n",
    "        dest.append(v)\n",
    "    \n",
    "    dgl_G = dgl.graph((src, dest), num_nodes=len(G.nodes))\n",
    "    \n",
    "    return features, adj_list, dgl_G\n",
    "\n",
    "def adj_matrix(adj_list):\n",
    "    row_idx = torch.LongTensor([k for k in range(len(adj_list.keys())) for v in range(len(adj_list[k]))])\n",
    "    col_idx = torch.LongTensor([v for k in range(len(adj_list.keys())) for v in adj_list[k]]) \n",
    "\n",
    "    idx = torch.vstack((row_idx, col_idx))\n",
    "    \n",
    "    return torch.sparse_coo_tensor(indices = idx, values = torch.ones(len(row_idx)), \n",
    "                                   size=[len(adj_list.keys()), len(adj_list.keys())])\n",
    "\n",
    "def make_label(batch_nodes):\n",
    "    batch_map = {n:i for i,n in enumerate(batch_nodes)}\n",
    "    neigh_list = [adj_list[n].intersection(batch_nodes) for n in batch_nodes]\n",
    "    #unique_nodes_list = list(set.union(*neigh_list))\n",
    "    #unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}\n",
    "    mask = torch.zeros(len(neigh_list), len(neigh_list)) \n",
    "    column_indices = [batch_map[n] for neigh in neigh_list for n in neigh]   \n",
    "    row_indices = [i for i in range(len(neigh_list)) for j in range(len(neigh_list[i]))]\n",
    "    mask[row_indices, column_indices] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def edge_coordinate(batch_nodes, neg=False):\n",
    "    if not neg:\n",
    "        neigh_dict = {n:adj_list[n] for n in batch_nodes}\n",
    "    else:\n",
    "        neigh_dict = {n:adj_list[n]^set(batch_nodes) for n in batch_nodes}\n",
    "    src = [k for k in neigh_dict.keys() for n in neigh_dict[k]]\n",
    "    dest = [n for v in neigh_dict.values() for n in v]\n",
    "    \n",
    "    return src, dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72547dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('graph_170k.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1f8a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_data, adj_list, dgl_G = load_data(G, feat_dir)\n",
    "#feat_data = normalize(torch.Tensor(feat_data), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a520ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e81544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]\n",
    "        \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "    \n",
    "    def get_scores(self, h):\n",
    "        return self.W2(F.relu(self.W1(h))).squeeze(1)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1c588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(feat_dim, emb_dim, G, features, adj_list):\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "\n",
    "    model = GraphSAGE(feat_dim, emb_dim)\n",
    "    pred = DotPredictor()\n",
    "#   model.cuda()\n",
    "\n",
    "    rand_indices = np.random.permutation(num_nodes)\n",
    "    test = list(rand_indices[:34000])\n",
    "    val = list(rand_indices[34000:51000])\n",
    "    train = list(rand_indices[51000:])\n",
    "    \n",
    "    train_g = dgl.remove_edges(G, val+test)\n",
    "    val_pos_g = dgl.graph(edge_coordinate(val), num_nodes=train_g.number_of_nodes())\n",
    "    val_neg_g = dgl.graph(edge_coordinate(val,neg=True), num_nodes=train_g.number_of_nodes())\n",
    "    print('Training starts:')\n",
    "\n",
    "    optimizer = torch.optim.SGD(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)                   \n",
    "    losses = []\n",
    "    for batch in range(100):\n",
    "        batch_nodes = train[:3000]\n",
    "        random.shuffle(train)  \n",
    "        start_time = time.time()\n",
    "        embed = model(train_g, features)\n",
    "        \n",
    "        train_pos_g = dgl.graph(edge_coordinate(batch_nodes), num_nodes=train_g.number_of_nodes())\n",
    "        train_neg_g = dgl.graph(edge_coordinate(batch_nodes,neg=True), num_nodes=train_g.number_of_nodes())\n",
    "        pos_score = pred(train_pos_g, embed)\n",
    "        neg_score = pred(train_neg_g, embed)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "        losses.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(batch, loss))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pos = pred(val_pos_g, embed)\n",
    "                neg = pred(val_neg_g, embed)\n",
    "                print('AUC', compute_auc(pos, neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd4b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "def train(feat_dim, emb_dim, G, features, adj_list):\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "\n",
    "    model = GraphSAGE(feat_dim, emb_dim)\n",
    "    pred = MLPPredictor(emb_dim)\n",
    "#   model.cuda()\n",
    "\n",
    "    rand_indices = np.random.permutation(num_nodes)\n",
    "    test = list(rand_indices[:34000])\n",
    "    val = list(rand_indices[34000:51000])\n",
    "    train = list(rand_indices[51000:])\n",
    "    \n",
    "    train_g = dgl.remove_edges(G, val+test)\n",
    "    #val_pos_g = dgl.graph(edge_coordinate(val), num_nodes=train_g.number_of_nodes())\n",
    "    #val_neg_g = dgl.graph(edge_coordinate(val,neg=True), num_nodes=train_g.number_of_nodes())\n",
    "    print('Training starts:')\n",
    "\n",
    "    optimizer = torch.optim.SGD(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)                   \n",
    "    losses = []\n",
    "    for batch in range(100):\n",
    "        batch_nodes = train[:3000]\n",
    "        random.shuffle(train)  \n",
    "        start_time = time.time()\n",
    "        embed = model(train_g, features)\n",
    "        \n",
    "        train_pos_g = dgl.graph(edge_coordinate(batch_nodes), num_nodes=train_g.number_of_nodes())\n",
    "        train_neg_g = dgl.graph(edge_coordinate(batch_nodes,neg=True), num_nodes=train_g.number_of_nodes())\n",
    "        pos_score = pred(train_pos_g, embed)\n",
    "        neg_score = pred(train_neg_g, embed)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "        losses.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end_time = time.time()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(batch, loss))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embed = model(val_g, features)\n",
    "                pos = pred(val_pos_g, embed)\n",
    "                neg = pred(val_neg_g, embed)\n",
    "                print('AUC', compute_auc(pos, neg))\n",
    "\n",
    "    return model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f38221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts:\n",
      "In epoch 0, loss: 0.5980200171470642\n",
      "In epoch 5, loss: 0.5898678302764893\n",
      "In epoch 10, loss: 0.5833808183670044\n",
      "In epoch 15, loss: 0.5780704021453857\n",
      "In epoch 20, loss: 0.5720557570457458\n",
      "In epoch 25, loss: 0.565000593662262\n",
      "In epoch 30, loss: 0.5577007532119751\n",
      "In epoch 35, loss: 0.553368330001831\n",
      "In epoch 40, loss: 0.550187349319458\n",
      "In epoch 45, loss: 0.5419141054153442\n",
      "In epoch 50, loss: 0.5378782749176025\n",
      "In epoch 55, loss: 0.5321746468544006\n",
      "In epoch 60, loss: 0.5262676477432251\n",
      "In epoch 65, loss: 0.5221739411354065\n",
      "In epoch 70, loss: 0.5163643956184387\n",
      "In epoch 75, loss: 0.5152520537376404\n",
      "In epoch 80, loss: 0.5065482258796692\n",
      "In epoch 85, loss: 0.5052351951599121\n",
      "In epoch 90, loss: 0.49707314372062683\n",
      "In epoch 95, loss: 0.4960591197013855\n"
     ]
    }
   ],
   "source": [
    "model, pred = train(14, 10, dgl_G, feat_data, adj_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
