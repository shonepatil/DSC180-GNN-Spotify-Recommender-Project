{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16d0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, 'src/data')\n",
    "sys.path.insert(0, 'src/dgl_graphsage')\n",
    "from src.api.spotifyAPI import SpotifyAPI\n",
    "from utils import load_data\n",
    "from train_updated import train\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl import save_graphs\n",
    "from dgl import load_graphs\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2e22e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6968bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Loading in the data. ~ 00:01:30\n",
    "# with open('config/data-params.json') as fh:\n",
    "#     data_cfg = json.load(fh)\n",
    "# feat_data, adj_list, dgl_G, uri_map = load_data(**data_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83258084",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d8b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './src/features')\n",
    "from build_features import load_data as graph_from_scratch\n",
    "import re\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5306c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses original files to make the graph from scratch\n",
    "\n",
    "# def scratch(feat_dir, normal=True):\n",
    "#     print('Loading feature data...')\n",
    "#     data = np.genfromtxt(feat_dir, delimiter=',', skip_header=True, dtype=str)\n",
    "#     features = np.array(np.delete(data[:,2:], -3, 1), dtype=float)\n",
    "#     if normal:\n",
    "#         features = normalize(torch.Tensor(features), dim=0)\n",
    "#     uris = data[:, 1]\n",
    "#     uris = [re.sub('spotify:track:', '', uri) for uri in uris]\n",
    "#     uri_map = {n: i for i,n in enumerate(uris)}\n",
    "    \n",
    "#     G = graph_from_scratch('./data/a13group1/data/', 'Spotify Playlist', 0, 0, 0)\n",
    "#     print('graph created')\n",
    "#     src, dest = [], [] \n",
    "#     adj_list = defaultdict(set)    \n",
    "#     for e in G.edges:\n",
    "#         u,v = uri_map[e[0]], uri_map[e[1]]\n",
    "#         adj_list[u].add(v)\n",
    "#         adj_list[v].add(u)\n",
    "#         src.append(u)\n",
    "#         dest.append(v)\n",
    "        \n",
    "#     src = torch.tensor(src)\n",
    "#     dest = torch.tensor(dest)\n",
    "        \n",
    "    \n",
    "#     print('adj list created')\n",
    "    \n",
    "#     dgl_G = dgl.graph((src, dest), num_nodes=len(G.nodes))\n",
    "#     return features, adj_list, dgl_G, uri_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3bd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Creates graph from scratch using from_networkx\n",
    "# results in double edges\n",
    "# '''\n",
    "# def scratch(feat_dir, normal=True):\n",
    "#     print('Loading feature data...')\n",
    "#     data = np.genfromtxt(feat_dir, delimiter=',', skip_header=True, dtype=str)\n",
    "#     features = np.array(np.delete(data[:,2:], -3, 1), dtype=float)\n",
    "#     if normal:\n",
    "#         features = normalize(torch.Tensor(features), dim=0)\n",
    "#     uris = data[:, 1]\n",
    "#     uris = [re.sub('spotify:track:', '', uri) for uri in uris]\n",
    "#     uri_map = {n: i for i,n in enumerate(uris)}\n",
    "    \n",
    "#     G = graph_from_scratch('./data/a13group1/data/', 'Spotify Playlist', 0, 0, 0)\n",
    "#     print('graph created')\n",
    "#     src, dest = [], [] \n",
    "#     adj_list = defaultdict(set)    \n",
    "#     for e in G.edges:\n",
    "#         u,v = uri_map[e[0]], uri_map[e[1]]\n",
    "#         adj_list[u].add(v)\n",
    "#         adj_list[v].add(u)\n",
    "#         src.append(u)\n",
    "#         dest.append(v)\n",
    "#     print('adj list created')\n",
    "    \n",
    "#     #dgl_G = dgl.graph((src, dest), num_nodes=len(G.nodes))\n",
    "#     dgl_G = dgl.from_networkx(G)\n",
    "#     return features, adj_list, dgl_G, uri_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a971386",
   "metadata": {},
   "source": [
    "### Currently the one I am using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2706842",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loads the double edged graph\n",
    "feat_dir = feature directory\n",
    "'''\n",
    "def load_double_edge(feat_dir, normal=True):\n",
    "    print('Loading feature data...')\n",
    "    data = np.genfromtxt(feat_dir, delimiter=',', skip_header=True, dtype=str)\n",
    "    features = np.array(np.delete(data[:,2:], -3, 1), dtype=float)\n",
    "    if normal:\n",
    "        features = normalize(torch.Tensor(features), dim=0)\n",
    "    uris = data[:, 1]\n",
    "    uris = [re.sub('spotify:track:', '', uri) for uri in uris]\n",
    "    uri_map = {n: i for i,n in enumerate(uris)}\n",
    "    listed = list(uri_map)\n",
    "    \n",
    "    G  = load_graphs(\"./data/a13group1/double_edges_170k.bin\")[0][0]\n",
    "    print('Loaded DGL Graph')\n",
    "    sources = G.edges()[0] \n",
    "    destinations = G.edges()[1]\n",
    "    \n",
    "    src, dest = [], [] \n",
    "    adj_list = defaultdict(set)\n",
    "    for e in range(len((G.edges()[0]))):\n",
    "        u,v = sources[e].item(), destinations[e].item()\n",
    "        adj_list[u].add(v)\n",
    "        adj_list[v].add(u)\n",
    "        src.append(u)\n",
    "        dest.append(v)\n",
    "        \n",
    "    \n",
    "    print('adj list created')\n",
    "    return features, adj_list, G, uri_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff4d19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 28 µs, total: 28 µs\n",
      "Wall time: 54.4 µs\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#feat_data, adj_list, dgl_G, uri_map = scratch(\"./data/a13group1/features/merged_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7f33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Graph if built from scratch\n",
    "# save_graphs(\"./data/a13group1/double_edges_170k.bin\", dgl_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25fa376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature data...\n",
      "Loaded DGL Graph\n",
      "adj list created\n",
      "CPU times: user 2min 44s, sys: 11.3 s, total: 2min 55s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "# Loading Graph ~ 3min\n",
    "%%time\n",
    "feat_data, adj_list, dgl_G, uri_map = load_double_edge(\"./data/a13group1/features/merged_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb30b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dgl_scratch = dgl.from_networkx(scratch_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa511d",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ff40b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pos edge: 26413580\n",
      "Validation pos edge: 518464\n",
      "Cuda enabled: True\n",
      "\n",
      "Training starts:\n",
      "In epoch 1 batch 1, loss: 0.7928540110588074\n",
      "In epoch 1 batch 6, loss: 0.6777392625808716\n",
      "In epoch 1 batch 11, loss: 0.49362197518348694\n",
      "In epoch 1 batch 16, loss: 0.22828425467014313\n",
      "In epoch 1 batch 21, loss: 0.10402873158454895\n",
      "\n",
      "Epoch 1 AUC:  0.4493406049153463\n",
      "In epoch 2 batch 1, loss: 0.1185450330376625\n",
      "In epoch 2 batch 6, loss: 0.14984646439552307\n",
      "In epoch 2 batch 11, loss: 0.13696223497390747\n",
      "In epoch 2 batch 16, loss: 0.12090416997671127\n",
      "In epoch 2 batch 21, loss: 0.10547196120023727\n",
      "\n",
      "Epoch 2 AUC:  0.4792098082859871\n",
      "In epoch 3 batch 1, loss: 0.10279714316129684\n",
      "In epoch 3 batch 6, loss: 0.1088569387793541\n",
      "In epoch 3 batch 11, loss: 0.10724322497844696\n",
      "In epoch 3 batch 16, loss: 0.10788120329380035\n",
      "In epoch 3 batch 21, loss: 0.10887868702411652\n",
      "\n",
      "Epoch 3 AUC:  0.5075558653971188\n",
      "In epoch 4 batch 1, loss: 0.11191188544034958\n",
      "In epoch 4 batch 6, loss: 0.10431034862995148\n",
      "In epoch 4 batch 11, loss: 0.10939474403858185\n",
      "In epoch 4 batch 16, loss: 0.10596068948507309\n",
      "In epoch 4 batch 21, loss: 0.1064852923154831\n",
      "\n",
      "Epoch 4 AUC:  0.5403840227505251\n",
      "In epoch 5 batch 1, loss: 0.10710249096155167\n",
      "In epoch 5 batch 6, loss: 0.10522700846195221\n",
      "In epoch 5 batch 11, loss: 0.10588975995779037\n",
      "In epoch 5 batch 16, loss: 0.10177680104970932\n",
      "In epoch 5 batch 21, loss: 0.10421241074800491\n",
      "\n",
      "Epoch 5 AUC:  0.5647927129829898\n",
      "In epoch 6 batch 1, loss: 0.10554549098014832\n",
      "In epoch 6 batch 6, loss: 0.10490766167640686\n",
      "In epoch 6 batch 11, loss: 0.10650316625833511\n",
      "In epoch 6 batch 16, loss: 0.1034151166677475\n",
      "In epoch 6 batch 21, loss: 0.10622327774763107\n",
      "\n",
      "Epoch 6 AUC:  0.5828069946581148\n",
      "In epoch 7 batch 1, loss: 0.09971427172422409\n",
      "In epoch 7 batch 6, loss: 0.10910573601722717\n",
      "In epoch 7 batch 11, loss: 0.11078133434057236\n",
      "In epoch 7 batch 16, loss: 0.10905677825212479\n",
      "In epoch 7 batch 21, loss: 0.10399036109447479\n",
      "\n",
      "Epoch 7 AUC:  0.5960425610422543\n",
      "In epoch 8 batch 1, loss: 0.10468930006027222\n",
      "In epoch 8 batch 6, loss: 0.10775591433048248\n",
      "In epoch 8 batch 11, loss: 0.10586883872747421\n",
      "In epoch 8 batch 16, loss: 0.10569951683282852\n",
      "In epoch 8 batch 21, loss: 0.10731495916843414\n",
      "\n",
      "Epoch 8 AUC:  0.6058446256396339\n",
      "In epoch 9 batch 1, loss: 0.10633201897144318\n",
      "In epoch 9 batch 6, loss: 0.10323347896337509\n",
      "In epoch 9 batch 11, loss: 0.1031116247177124\n",
      "In epoch 9 batch 16, loss: 0.10581815987825394\n",
      "In epoch 9 batch 21, loss: 0.10738073289394379\n",
      "\n",
      "Epoch 9 AUC:  0.6132975184493387\n",
      "In epoch 10 batch 1, loss: 0.10649297386407852\n",
      "In epoch 10 batch 6, loss: 0.10881420224905014\n",
      "In epoch 10 batch 11, loss: 0.10955264419317245\n",
      "In epoch 10 batch 16, loss: 0.10303851962089539\n",
      "In epoch 10 batch 21, loss: 0.10954988747835159\n",
      "\n",
      "Epoch 10 AUC:  0.6189667468267881\n",
      "CPU times: user 4min 55s, sys: 17.5 s, total: 5min 12s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the Model. GPU ~ 00:00:40\n",
    "with open('config/model-params.json') as fh:\n",
    "            model_cfg = json.load(fh)\n",
    "model, pred = train(dgl_G, feat_data, adj_list, **model_cfg)\n",
    "\n",
    "# Put everything on CPU\n",
    "model = model.to('cpu')\n",
    "pred = pred.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a784ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embeddings\n",
    "z = model(dgl_G, feat_data)\n",
    "\n",
    "# Create Predictions\n",
    "# In the form of the strength of the connection between source, destination from dgl_G.edges()\n",
    "preds = pred(dgl_G, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63eb93cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(n_neighbors=25, radius=0.4)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Nearest Neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=25, radius=0.4)\n",
    "neigh.fit(feat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ed7fc",
   "metadata": {},
   "source": [
    "# Get Random Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ea2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get a list of eligible slice files (first 10000 playlists)\n",
    "thelist: list of directories\n",
    "'''\n",
    "def get_eligible(thelist):\n",
    "    eligible = []\n",
    "    for x in thelist:\n",
    "        nums = pd.Series(x.strip('mpd.slice.json').split('-')).astype(int)\n",
    "        if nums[0] <= 9999:\n",
    "            eligible.append(x)\n",
    "    return eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7eeffa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets random playlist\n",
    "Gets the track names of the original tracks in the playlist\n",
    "'''\n",
    "def get_playlist():\n",
    "    data_path = (os.path.join(os.path.expanduser('~'), '/teams/DSC180A_FA21_A00/a13group1/data/'))\n",
    "    file_samp = np.random.choice(get_eligible(pd.Series(os.listdir(os.path.join(os.path.expanduser('~'), '/teams/DSC180A_FA21_A00/a13group1/data/')))), replace=True)\n",
    "    fname = os.path.join(data_path, file_samp)\n",
    "    with open(fname) as f:\n",
    "        data = json.load(f)\n",
    "        item = np.random.choice(data['playlists'])\n",
    "    print(fname)    \n",
    "    print('Playlist ID:', item['pid'])\n",
    "    print('Playlist Length:', len(item['tracks']))\n",
    "    \n",
    "    # Get track names---artist\n",
    "    original_tracks = []\n",
    "    for i in range(len(item['tracks'])):\n",
    "        name = item['tracks'][i]['track_name']+'---'+item['tracks'][i]['artist_name']\n",
    "        original_tracks.append(name)\n",
    "        \n",
    "    # Get track uris\n",
    "    seeds = []\n",
    "    for i in item['tracks']:\n",
    "        uri = i['track_uri'].split(':')[-1]\n",
    "        seeds.append(uri)\n",
    "        \n",
    "    return item, original_tracks, seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8ab0ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teams/DSC180A_FA21_A00/a13group1/data/mpd.slice.9000-9999.json\n",
      "Playlist ID: 9266\n",
      "Playlist Length: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Celebraré Tu Amor---Jesús Adrián Romero',\n",
       " 'Alzad Oh Puertas---Jesús Adrián Romero',\n",
       " 'Tu Nos Creaste---Jesús Adrián Romero',\n",
       " 'Abre Los Cielos---Jesús Adrián Romero',\n",
       " 'Un Destello De Tu Gloria---Jesús Adrián Romero',\n",
       " 'Al Estar Ante Ti---Jesús Adrián Romero & Alejandro Del Bosque',\n",
       " 'No Me Soltarás---Rojo',\n",
       " 'Vino Celestial---Miel San Marcos',\n",
       " 'El Santo De Israel---Miel San Marcos',\n",
       " 'Vino Celestial---Miel San Marcos',\n",
       " 'Enamorado de Ti---René González']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item, original_tracks, seeds = get_playlist()\n",
    "original_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac955157",
   "metadata": {},
   "source": [
    "# Recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d0207620",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates dictionary of highest scored recommendation (of songs not in playlist) for each song in playlist\n",
    "seeds: list of track uris from user's playlist\n",
    "dgl_G: DGL Graph\n",
    "z: embeddings generated from model\n",
    "pred: predictor from model\n",
    "feat_data: matrix of feature data\n",
    "'''\n",
    "def recommend(seeds, dgl_G, z, pred, neigh, feat_data):\n",
    "\n",
    "    listed = list(uri_map) #parse through uri map for uri --> integer\n",
    "\n",
    "    score_dict = defaultdict(dict)\n",
    "    for s in seeds:\n",
    "        s = uri_map[s]\n",
    "        _, candidates = dgl_G.out_edges(s, form='uv')\n",
    "        s_embed = z[s].unsqueeze(dim=0)\n",
    "        edge_embeds = [torch.cat([s_embed, z[c.item()].unsqueeze(dim=0)],1) for c in candidates]\n",
    "        print('Node Value:', s, 'Possible Recs:', len(edge_embeds))\n",
    "        edge_embeds = torch.cat(edge_embeds, 0)\n",
    "        scores = pred.W2(F.relu(pred.W1(edge_embeds))).squeeze(1)\n",
    "        val = list(zip(candidates.detach().numpy(), scores.detach().numpy()))\n",
    "        val.sort(key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        # Make sure the song is not already in the playlist\n",
    "        # score_dict[s] = val[0]\n",
    "        inc = 0\n",
    "        while True and inc < len(val):\n",
    "            if listed[val[inc][0]] not in seeds:\n",
    "                score_dict[s] = val[inc][0]\n",
    "                break\n",
    "            if inc == (len(val) - 1):\n",
    "                # If no co-occurence, use 5-NN based on features -- COLD START\n",
    "                print('None Found, Using Feature Data Instead')\n",
    "                closest = neigh.kneighbors(feat_data[[s]], 25, return_distance=False)[0]\n",
    "                for i in closest:\n",
    "                    if listed[i] not in seeds:\n",
    "                        score_dict[s] = i\n",
    "                        break\n",
    "                break\n",
    "                    \n",
    "            else:\n",
    "                inc += 1\n",
    "                \n",
    "    # Get uris            \n",
    "    uri_recs = []\n",
    "    for i in score_dict.keys():\n",
    "        cur_uri = listed[score_dict[i]]\n",
    "        uri_recs.append(cur_uri)\n",
    "        \n",
    "    return uri_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4384e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Value: 103404 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 102021 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 103838 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 131896 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 10733 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 32115 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 46453 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 50303 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 63782 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 50303 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n",
      "Node Value: 64778 Possible Recs: 9\n",
      "None Found, Using Feature Data Instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3mDL7gITYAea1T2nJBs5Tk',\n",
       " '7IN4zUEZQJkyATFepIrNWP',\n",
       " '6IL6dgzFkfiRgHORMlxkMf',\n",
       " '2eHFk44RlGGfcJhYioirFR',\n",
       " '641BnSVI1ydg9RWBSKvaXv',\n",
       " '4PrzTV80lUwZlZbvd2oswH',\n",
       " '2BJMHc2oMWUv0bimChLsvG',\n",
       " '0N6W6IJi7zYAUhKJULGDaH',\n",
       " '6CE9kx5HJSH2D836t5QouD',\n",
       " '1yw66ZPsfqblI4PFcEdIKe']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri_recs = recommend(seeds, dgl_G, z, pred, neigh, feat_data)\n",
    "uri_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5205b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'77aasEzxEXE13suFG6npRE'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listed = list(uri_map) #parse through uri map for uri --> integer\n",
    "listed[155421]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d0e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5832,\n",
       " 13024,\n",
       " 20176,\n",
       " 24311,\n",
       " 31689,\n",
       " 34816,\n",
       " 42293,\n",
       " 47402,\n",
       " 65694,\n",
       " 101105,\n",
       " 102554,\n",
       " 114408,\n",
       " 120586,\n",
       " 137468,\n",
       " 138034,\n",
       " 150486,\n",
       " 151243,\n",
       " 159998,\n",
       " 162902}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list[155421]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee808838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([155421, 155421, 155421, 155421, 155421, 155421, 155421, 155421, 155421,\n",
       "         155421, 155421, 155421, 155421, 155421, 155421, 155421, 155421, 155421,\n",
       "         155421]),\n",
       " tensor([159998, 137468, 101105, 102554,  47402,   5832, 162902,  24311, 138034,\n",
       "         150486,  65694, 151243,  34816,  20176,  42293, 120586,  13024,  31689,\n",
       "         114408]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_G.out_edges(155421, form='uv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76a839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8137268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27bed56f",
   "metadata": {},
   "source": [
    "# Translate Codes with Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "56d5ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'ad2536ed7a914d66b89b80fb3a500787'\n",
    "client_secret = '8c5f45fb008d4bc5bf909ec46d076b65'\n",
    "\n",
    "spotify = SpotifyAPI(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "34ee2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spotify(query, api, num):\n",
    "    chunk = api.get_resource(query, 'tracks', 'v1')\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d210b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_names(uri_recs, api, sleep_time):\n",
    "    rec_track_names = []\n",
    "    for i in uri_recs:\n",
    "        one = get_data_spotify(i, api, 1)\n",
    "        trackname = one['tracks'][0]['name']\n",
    "\n",
    "        firstartist = one['tracks'][0]['artists'][0]['name']\n",
    "\n",
    "        the_rec = trackname+'---'+firstartist\n",
    "        rec_track_names.append(the_rec)\n",
    "\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "    return rec_track_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "651264c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 348 ms, sys: 44 ms, total: 392 ms\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rec_track_names = get_rec_names(uri_recs, spotify, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0c543868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Celebraré Tu Amor---Jesús Adrián Romero',\n",
       " 'Alzad Oh Puertas---Jesús Adrián Romero',\n",
       " 'Tu Nos Creaste---Jesús Adrián Romero',\n",
       " 'Abre Los Cielos---Jesús Adrián Romero',\n",
       " 'Un Destello De Tu Gloria---Jesús Adrián Romero',\n",
       " 'Al Estar Ante Ti---Jesús Adrián Romero & Alejandro Del Bosque',\n",
       " 'No Me Soltarás---Rojo',\n",
       " 'Vino Celestial---Miel San Marcos',\n",
       " 'El Santo De Israel---Miel San Marcos',\n",
       " 'Vino Celestial---Miel San Marcos',\n",
       " 'Enamorado de Ti---René González']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "028a6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Voodoo - Live---Godsmack                                                     1\n",
       "Feel Good Inc. - Live at Manchester Opera House---Gorillaz                   1\n",
       "Can't Get Enough - Live At The Wembley Arena, London / 2010---Bad Company    1\n",
       "No Basta---Franco De Vita                                                    1\n",
       "Ten Thousand Words---The Avett Brothers                                      1\n",
       "---                                                                          1\n",
       "Not Ashamed---Jeremy Camp                                                    1\n",
       "Hokages Furneral - Dance Mix---The Game Music Committee                      1\n",
       "All For Love---Planetshakers                                                 1\n",
       "Make Me Believe in You---Curtis Mayfield                                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rec_track_names).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93147d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
